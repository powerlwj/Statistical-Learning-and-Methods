{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用K近邻算法对breast cancer数据进行评估，原则：近朱者赤近墨者黑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "先对数据进行预览，主要目的是将diagnosis的类别数据转为数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "            ...             radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           ...                    25.38          17.33           184.60   \n",
       "1           ...                    24.99          23.41           158.80   \n",
       "2           ...                    23.57          25.53           152.50   \n",
       "3           ...                    14.91          26.50            98.87   \n",
       "4           ...                    22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"F:\\Machine Learning\\ML\\Data\\Datasets\\Breast-Cancer//train.csv \")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(fileName):\n",
    "    '''\n",
    "    加载breast cancer数据集\n",
    "    :param fileName:要加载的数据集路径\n",
    "    :return: list形式的数据集及标记\n",
    "    '''\n",
    "    print('数据读取')\n",
    "    # 存放数据及标记的list\n",
    "    dataArr = []; labelArr = []\n",
    "    # 打开文件\n",
    "    fr = open(fileName, 'r')\n",
    "    # 将文件按行读取\n",
    "    lines=fr.readlines()\n",
    "    for line in lines[1:]:\n",
    "        # 对每一行数据按切割福','进行切割，返回字段列表\n",
    "        curLine = line.strip().split(',')\n",
    "        if curLine[1]=='M':\n",
    "            labelArr.append(-1)\n",
    "        else:\n",
    "            labelArr.append(1)\n",
    "        #存放标记\n",
    "        dataArr.append([float(num) for num in curLine[2:]])\n",
    "    #返回data和label\n",
    "    return dataArr, labelArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcDist(x1, x2):\n",
    "    '''\n",
    "    计算两个样本点向量之间的距离\n",
    "    使用的是欧氏距离，即 样本点每个元素相减的平方，再求和，再开方\n",
    "    欧式举例公式这里不方便写，可以百度或谷歌欧式距离（也称欧几里得距离）\n",
    "    :param x1:向量1\n",
    "    :param x2:向量2\n",
    "    :return:向量之间的欧式距离\n",
    "    '''\n",
    "    return np.sqrt(np.sum(np.square(x1 - x2)))\n",
    "    #曼哈顿距离计算公式\n",
    "    # return np.sum(x1 - x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClosest(trainDataMat, trainLabelMat, x, topK):\n",
    "    '''\n",
    "    预测样本x的标记。\n",
    "    获取方式通过找到与样本x最近的topK个点，并查看它们的标签。\n",
    "    查找里面占某类标签最多的那类标签\n",
    "    :param trainDataMat:训练集数据集\n",
    "    :param trainLabelMat:训练集标签集\n",
    "    :param x:要预测的样本x\n",
    "    :param topK:选择参考最邻近样本的数目（样本数目的选择关系到正确率）\n",
    "    :return:预测的标记\n",
    "    '''\n",
    "    #建立一个存放向量x与每个训练集中样本距离的列表\n",
    "    #列表的长度为训练集的长度，distList[i]表示x与训练集中第\n",
    "    ## i个样本的距离\n",
    "    distList = [0] * len(trainLabelMat)\n",
    "    #遍历训练集中所有的样本点，计算与x的距离\n",
    "    for i in range(len(trainDataMat)):\n",
    "        #获取训练集中当前样本的向量\n",
    "        x1 = trainDataMat[i]\n",
    "        #计算向量x与训练集样本x的距离\n",
    "        curDist = calcDist(x1, x)\n",
    "        #将距离放入对应的列表位置中\n",
    "        distList[i] = curDist\n",
    "    #对距离列表进行排序\n",
    "    #argsort：函数将数组的值从小到大排序后，并按照其相对应的索引值输出\n",
    "    #例如：\n",
    "    #   >>> x = np.array([3, 1, 2])\n",
    "    #   >>> np.argsort(x)\n",
    "    #   array([1, 2, 0])\n",
    "    #返回的是列表中从小到大的元素索引值，对于我们这种需要查找最小距离的情况来说很合适\n",
    "    #array返回的是整个索引值列表，我们通过[:topK]取列表中前topL个放入list中。\n",
    "    topKList = np.argsort(np.array(distList))[:topK]        #升序排序\n",
    "    #建立一个长度时的列表，用于选择数量最多的标记\n",
    "    #3.2.4提到了分类决策使用的是投票表决，topK个标记每人有一票，在数组中每个标记代表的位置中投入\n",
    "    #自己对应的地方，随后进行唱票选择最高票的标记\n",
    "    labelList = [0] * 2\n",
    "    #对topK个索引进行遍历\n",
    "    for index in topKList:\n",
    "        #trainLabelMat[index]：在训练集标签中寻找topK元素索引对应的标记\n",
    "        #int(trainLabelMat[index])：将标记转换为int（实际上已经是int了，但是不int的话，报错）\n",
    "        #labelList[int(trainLabelMat[index])]：找到标记在labelList中对应的位置\n",
    "        #最后加1，表示投了一票\n",
    "        labelList[int(trainLabelMat[index])] += 1\n",
    "    #max(labelList)：找到选票箱中票数最多的票数值\n",
    "    #labelList.index(max(labelList))：再根据最大值在列表中找到该值对应的索引，等同于预测的标记\n",
    "    return labelList.index(max(labelList))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(trainDataArr, trainLabelArr, testDataArr, testLabelArr, topK):\n",
    "    '''\n",
    "    测试正确率\n",
    "    :param trainDataArr:训练集数据集\n",
    "    :param trainLabelArr: 训练集标记\n",
    "    :param testDataArr: 测试集数据集\n",
    "    :param testLabelArr: 测试集标记\n",
    "    :param topK: 选择多少个邻近点参考\n",
    "    :return: 正确率\n",
    "    '''\n",
    "    print('start test')\n",
    "    #将所有列表转换为矩阵形式，方便运算\n",
    "    trainDataMat = np.mat(trainDataArr); trainLabelMat = np.mat(trainLabelArr).T\n",
    "    testDataMat = np.mat(testDataArr); testLabelMat = np.mat(testLabelArr).T\n",
    "    #错误值计数\n",
    "    errorCnt = 0\n",
    "    #遍历测试集，对每个测试集样本进行测试\n",
    "    #和return也要相应的更换注释行\n",
    "    for i in range(len(testDataMat)):\n",
    "        print('test %d:%d'%(i, len(trainDataArr)))\n",
    "        #读取测试集当前测试样本的向量\n",
    "        x = testDataMat[i]\n",
    "        #获取预测的标记\n",
    "        y = getClosest(trainDataMat, trainLabelMat, x, topK)\n",
    "        #如果预测标记与实际标记不符，错误值计数加1\n",
    "        if y != testLabelMat[i]: errorCnt += 1\n",
    "    #返回正确率\n",
    "    return 1 - (errorCnt / len(testDataMat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据读取\n",
      "数据读取\n",
      "start test\n",
      "test 0:469\n",
      "test 1:469\n",
      "test 2:469\n",
      "test 3:469\n",
      "test 4:469\n",
      "test 5:469\n",
      "test 6:469\n",
      "test 7:469\n",
      "test 8:469\n",
      "test 9:469\n",
      "test 10:469\n",
      "test 11:469\n",
      "test 12:469\n",
      "test 13:469\n",
      "test 14:469\n",
      "test 15:469\n",
      "test 16:469\n",
      "test 17:469\n",
      "test 18:469\n",
      "test 19:469\n",
      "test 20:469\n",
      "test 21:469\n",
      "test 22:469\n",
      "test 23:469\n",
      "test 24:469\n",
      "test 25:469\n",
      "test 26:469\n",
      "test 27:469\n",
      "test 28:469\n",
      "test 29:469\n",
      "test 30:469\n",
      "test 31:469\n",
      "test 32:469\n",
      "test 33:469\n",
      "test 34:469\n",
      "test 35:469\n",
      "test 36:469\n",
      "test 37:469\n",
      "test 38:469\n",
      "test 39:469\n",
      "test 40:469\n",
      "test 41:469\n",
      "test 42:469\n",
      "test 43:469\n",
      "test 44:469\n",
      "test 45:469\n",
      "test 46:469\n",
      "test 47:469\n",
      "test 48:469\n",
      "test 49:469\n",
      "test 50:469\n",
      "test 51:469\n",
      "test 52:469\n",
      "test 53:469\n",
      "test 54:469\n",
      "test 55:469\n",
      "test 56:469\n",
      "test 57:469\n",
      "test 58:469\n",
      "test 59:469\n",
      "test 60:469\n",
      "test 61:469\n",
      "test 62:469\n",
      "test 63:469\n",
      "test 64:469\n",
      "test 65:469\n",
      "test 66:469\n",
      "test 67:469\n",
      "test 68:469\n",
      "test 69:469\n",
      "test 70:469\n",
      "test 71:469\n",
      "test 72:469\n",
      "test 73:469\n",
      "test 74:469\n",
      "test 75:469\n",
      "test 76:469\n",
      "test 77:469\n",
      "test 78:469\n",
      "test 79:469\n",
      "test 80:469\n",
      "test 81:469\n",
      "test 82:469\n",
      "test 83:469\n",
      "test 84:469\n",
      "test 85:469\n",
      "test 86:469\n",
      "test 87:469\n",
      "test 88:469\n",
      "test 89:469\n",
      "test 90:469\n",
      "test 91:469\n",
      "test 92:469\n",
      "test 93:469\n",
      "test 94:469\n",
      "test 95:469\n",
      "test 96:469\n",
      "test 97:469\n",
      "test 98:469\n",
      "test 99:469\n",
      "accur is:77 %\n",
      "time span: 0.7360024452209473\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#获取训练集\n",
    "trainData, trainLabel = loadData('F:\\Machine Learning\\ML\\Data\\Datasets\\Breast-Cancer//train.csv ')\n",
    "#获取测试集\n",
    "testData, testLabel = loadData('F:\\Machine Learning\\ML\\Data\\Datasets\\Breast-Cancer//test.csv ')\n",
    "#计算测试集正确率\n",
    "accur = test(trainData, trainLabel, testData, testLabel, 10)\n",
    "#打印正确率\n",
    "print('accur is:%d'%(accur * 100), '%')\n",
    "end = time.time()\n",
    "#显示花费时间\n",
    "print('time span:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
